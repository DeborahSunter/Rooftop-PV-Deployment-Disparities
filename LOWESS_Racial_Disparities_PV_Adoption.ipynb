{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.ticker as mtick\n",
    "import statsmodels.api as sm\n",
    "from scipy.interpolate import interp1d\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USER INPUTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Majority Level\n",
    "# The majority level sets the percentage of the census tract population that must self-identify as the same \n",
    "# race/ethnicity in order for the census tract to be classified as that race/ethnicity. We had defined majority \n",
    "# as 50% and strong-majority as 75%.\n",
    "majority_level = 50\n",
    "\n",
    "# Variable of Interest\n",
    "# For the LOWESS analysis, we explore racial disparity in rooftop PV deployment as a function of median household \n",
    "# income and the percentage of households occupied by renters. If you would like to generate plots with the median \n",
    "# household income along the x-axis (similar to Figures 2, 5, S1, and S5), use 'median_income' as your variable of \n",
    "# interest. If you would like to generate plots with the percentage of households occupied by renters (similar to \n",
    "# Figure 3), use 'rental_ratio' as your variable of interest. If you would like to generate plots with the median\n",
    "# surplus household income along the x-axis (similar to Figure S2), use 'surplus_income' as your variable of interest.\n",
    "variable_of_interest = 'median_income'\n",
    "\n",
    "# Confidence Interval\n",
    "# We used a 90% confidence interval (CI) in the published analysis but one may choose to explore a different CI.\n",
    "CI = 90\n",
    "\n",
    "# Exclude Census Tracts Without Rooftop PV Installations\n",
    "# To explore the potential issue of 'seeding', we excluded census tracts without rooftop PV installations to create\n",
    "# Figures 5 and S5. If you would like to reproduce these figures and exclude census tracts without rooftop PV use \n",
    "# True; otherwise, use False. Using False will include all census tracts in the analysis and allow you to reproduce \n",
    "# Figures 2, 3, and S1.\n",
    "exclude_census_tracts_without_rooftop_PV = False\n",
    "\n",
    "# Smoothing Parameter, f\n",
    "# The subsets of data used for each weighted least squares fit in LOWESS are determined by a nearest neighbors \n",
    "# algorithm. A smoothing parameter, f, determines the fraction of the data that is used to fit each local regression.\n",
    "# Large values of f produce the smoothest functions that wiggle the least in response to fluctuations in the data. The\n",
    "# smaller f is, the closer the regression function will conform to the data. Using too small a value of f is not \n",
    "# desirable, however, since the regression function will eventually start to capture the random error in the data. \n",
    "# When the variable \"smoothing_factor_default\" is set to True the smoothing factor is set to 1 to be consistent with\n",
    "# all reported figures in article. If you wish to set the smoothing parameter to another value, you may modify the \n",
    "# smoothing_parameter function in the code below. When this value is set to False, a range of smoothing parameters are\n",
    "# considered and chosen to minimize the sum of the squared residuals.\n",
    "smoothing_factor_default = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demographic Data\n",
    "# ACS 2015 Planning database available at https://www.census.gov/data/datasets/2015/adrm/research/2015-planning-database.html \n",
    "DemographicData = pd.read_csv('PDB_2015_Tract.csv', encoding = \"ISO-8859-1\")\n",
    "DemographicData = DemographicData[['GIDTR', 'State_name', \n",
    "                                   'Renter_Occp_HU_ACS_09_13', 'Owner_Occp_HU_ACS_09_13', \n",
    "                                   'pct_NH_Asian_alone_ACS_09_13', 'pct_NH_Blk_alone_ACS_09_13',\n",
    "                                   'pct_Hispanic_ACS_09_13', 'pct_NH_White_alone_ACS_09_13',\n",
    "                                   'Med_HHD_Inc_ACS_09_13']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project Sunroof Data\n",
    "# Data in this GitHub repository was updated in August 2021.\n",
    "# More recently updated data can be found at https://www.google.com/get/sunroof/data-explorer/\n",
    "SunroofData = pd.read_csv('project-sunroof-census_tract.csv')\n",
    "SunroofData = SunroofData[['region_name', 'count_qualified', 'existing_installs_count', 'percent_covered', 'percent_qualified']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cost of Living Data\n",
    "# Updated data can be found at https://livingwage.mit.edu/\n",
    "# Data corresponds to the required annual income before taxes for a family of 2 adults and 2 children.\n",
    "LivingWageData = pd.read_csv('cost_of_living_by_county.csv')\n",
    "LivingWageData = LivingWageData[['county', 'required_income']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLEAN DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert median household income from a string to a float and rename median_income\n",
    "DemographicData['Med_HHD_Inc_ACS_09_13'] = DemographicData['Med_HHD_Inc_ACS_09_13'].replace({'\\$': '', ',': ''}, regex=True).astype(float)\n",
    "DemographicData = DemographicData.rename(columns={'Med_HHD_Inc_ACS_09_13': 'median_income'})\n",
    "\n",
    "# Merge Google Project Sunroof data with Demographic data from ACS\n",
    "data = SunroofData.merge(DemographicData,left_on='region_name',right_on='GIDTR')\n",
    "\n",
    "# Remove census tracts where Google Project Sunroof analyzed < 95% of all buildings in the census tract.\n",
    "data = data[data.percent_covered >= 95]\n",
    "\n",
    "# Remove census tracts where there is no potential to install rooftop PV\n",
    "data = data[data.count_qualified !=0]\n",
    "\n",
    "# Remove census tracts with median household income below the 2013 poverty threshold for a 4-person household \n",
    "# https://www.census.gov/data/tables/time-series/demo/income-poverty/historical-poverty-thresholds.html\n",
    "data = data[data.median_income >= 23834] \n",
    "\n",
    "data = data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the user input a request to remove census tracts without any rooftop solar from the analysis, remove these tracts\n",
    "if exclude_census_tracts_without_rooftop_PV == True:\n",
    "    data = data[data.existing_installs_count != 0]\n",
    "    data = data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the user input would like to study surplus income, merge the Living Wage data.\n",
    "# Note that the Living Wage data does not include US territories.\n",
    "if variable_of_interest == 'surplus_income':\n",
    "    for i in range(0,len(data)):\n",
    "        data.at[i,'state_county'] = int(data.GIDTR[i].astype(str)[:-6])\n",
    "    # Merge Living Wage data with the rest of the data\n",
    "    data = data.merge(LivingWageData,left_on='state_county',right_on='county')\n",
    "    data['surplus_income'] = data['median_income'] - data['required_income']\n",
    "    data = data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CALCULATE STATE NORMALIZED SOLAR DEPLOYMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equation 1 in the Nature Sustainability analysis\n",
    "# Compute the percentage of buildings with existing rooftop PV relative to the total number of buildings with roofs \n",
    "# that qualify to support PV based on the algorithm and criteria to identify appropriate potential rooftop space for \n",
    "# PV deployment set forth by Google Project Sunroof. This is the solar deployment rate.\n",
    "data['pct_current_installs_relative_to_total_installs']=data['existing_installs_count']/data['count_qualified']*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equation 2 in the Nature Sustainability analysis\n",
    "# Normalize the solar deployment rate by the average solar deployment rate in each state.\n",
    "# This mitigates the effects of variations across states, such as available solar resources, incentive programs and\n",
    "# policies, and electricity prices.\n",
    "df_state_mean = pd.DataFrame(columns=('State_name', 'state_mean_existing_installation_relative_to_potential'))\n",
    "\n",
    "for state in set(data.State_name):\n",
    "    mean_state = np.mean(data['pct_current_installs_relative_to_total_installs'][(data['State_name'] == state)])\n",
    "    df_state_mean.loc[state] = [state, mean_state]\n",
    "\n",
    "data = pd.merge(data, df_state_mean, on='State_name')\n",
    "data['normalized_existing_installation']=data['pct_current_installs_relative_to_total_installs']/data['state_mean_existing_installation_relative_to_potential']\n",
    "\n",
    "# Remove states or territories where Google Project Sunroof hasn't identified any rooftop solar installations\n",
    "data = data[data.state_mean_existing_installation_relative_to_potential !=0]\n",
    "data = data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GROUP CENSUS TRACTS BY THEIR MAJORITY RACE/ETHNICITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframes for each race/ethnicity in the study\n",
    "df_asian       = pd.DataFrame(columns=[variable_of_interest, 'normalized_existing_installation'])\n",
    "df_black       = pd.DataFrame(columns=[variable_of_interest, 'normalized_existing_installation'])\n",
    "df_hisp        = pd.DataFrame(columns=[variable_of_interest, 'normalized_existing_installation'])\n",
    "df_white       = pd.DataFrame(columns=[variable_of_interest, 'normalized_existing_installation'])\n",
    "df_no_majority = pd.DataFrame(columns=[variable_of_interest, 'normalized_existing_installation'])\n",
    "\n",
    "# Calculate the fraction of renter occupied households\n",
    "if variable_of_interest == 'rental_ratio':\n",
    "    data['rental_ratio'] = 100*data.Renter_Occp_HU_ACS_09_13/(data.Renter_Occp_HU_ACS_09_13+data.Owner_Occp_HU_ACS_09_13)\n",
    "\n",
    "# Filter data by majority level to populate each race/ethnicity dataframe\n",
    "for i in range(0, len(data)):\n",
    "    if data['pct_NH_Asian_alone_ACS_09_13'][i] >= majority_level:\n",
    "        df_asian.loc[i] = [data[variable_of_interest][i], data['normalized_existing_installation'][i]]\n",
    "    elif data['pct_NH_Blk_alone_ACS_09_13'][i] >= majority_level:\n",
    "        df_black.loc[i] = [data[variable_of_interest][i], data['normalized_existing_installation'][i]]\n",
    "    elif data['pct_Hispanic_ACS_09_13'][i] >= majority_level:\n",
    "        df_hisp.loc[i] = [data[variable_of_interest][i], data['normalized_existing_installation'][i]]\n",
    "    elif data['pct_NH_White_alone_ACS_09_13'][i] >= majority_level:\n",
    "        df_white.loc[i] = [data[variable_of_interest][i], data['normalized_existing_installation'][i]]\n",
    "    else:\n",
    "        df_no_majority.loc[i] = [data[variable_of_interest][i], data['normalized_existing_installation'][i]]\n",
    "\n",
    "# Reindex\n",
    "df_asian = df_asian.reset_index(drop=True)\n",
    "df_black = df_black.reset_index(drop=True)\n",
    "df_hisp  = df_hisp.reset_index(drop=True)\n",
    "df_white = df_white.reset_index(drop=True)\n",
    "df_no_majority = df_no_majority.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOWESS ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform LOWESS and determine the sum of the squared residuals\n",
    "def lowess_sse(df, variable_of_interest, fraction):\n",
    "    lowess = sm.nonparametric.lowess(df['normalized_existing_installation'], df[variable_of_interest], frac=fraction)\n",
    "    lowess_x = list(zip(*lowess))[0]\n",
    "    lowess_y = list(zip(*lowess))[1]\n",
    "    squared_residuals = (df.normalized_existing_installation-lowess_y)**2\n",
    "    sum_squared_residuals = sum(squared_residuals)\n",
    "    return sum_squared_residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the optimal LOWESS smoothing parameter, f, that minimizes the sum of the squared residuals\n",
    "def smoothing_parameter(df, variable_of_interest, smoothing_factor_default):\n",
    "    if smoothing_factor_default == True:\n",
    "        optimal_fraction = 1\n",
    "    if smoothing_factor_default == False:\n",
    "        mses = pd.DataFrame()\n",
    "        fold = 0\n",
    "        \n",
    "        # Perform a 5-Fold Cross-Validation\n",
    "        kf = KFold(n_splits=5, shuffle=True, random_state=0) \n",
    "        for train_index, val_index in kf.split(df):\n",
    "            # Separate each array into respective variables\n",
    "            df_fold_train = df.iloc[train_index]\n",
    "            df_fold_val = df.iloc[val_index]\n",
    "\n",
    "            MSE_array = []\n",
    "            interval = 0.05\n",
    "            fractions_considered = np.arange(0.2,1+interval,interval)\n",
    "            for fraction in fractions_considered:\n",
    "                # Fit LOWESS model\n",
    "                lowess = sm.nonparametric.lowess(df_fold_train['normalized_existing_installation'], df_fold_train[variable_of_interest], frac=fraction)\n",
    "                lowess_x = list(zip(*lowess))[0]\n",
    "                lowess_y = list(zip(*lowess))[1]\n",
    "                f = interp1d(lowess_x, lowess_y, bounds_error=False) \n",
    "                y_pred = f(df_fold_val[variable_of_interest])\n",
    "            \n",
    "                # Calculate the mean squared error\n",
    "                #   If the validation set has data points outside the range of the training set, \n",
    "                #   an error would occur in the calculation of the MSE. Therefore, validation points outside\n",
    "                #   the training range are removed for this calculation\n",
    "                if np.isnan(y_pred).any()==True:\n",
    "                    y_comparison = pd.DataFrame({'y_pred': np.array(y_pred), 'y_fold_val': np.array(df_fold_val['normalized_existing_installation'])}, columns=['y_pred', 'y_fold_val'])\n",
    "                    y_comparison = y_comparison.dropna()\n",
    "                    MSE = mean_squared_error(y_comparison.y_fold_val, y_comparison.y_pred)\n",
    "                else:\n",
    "                    MSE = mean_squared_error(df_fold_val['normalized_existing_installation'], y_pred)\n",
    "                MSE_array.append(MSE)\n",
    "\n",
    "            mses[fold] = MSE_array\n",
    "            fold = fold+1\n",
    "\n",
    "        # Average the MSE across folds\n",
    "        mses['mses_ave'] = mses.mean(axis=1)\n",
    "\n",
    "        # Determine the minimum average MSE and with which fraction does it occur\n",
    "        MSE_ave_min = min(mses.mses_ave)\n",
    "        f_MSE_ave_min_index = mses['mses_ave'].idxmin()\n",
    "        optimal_fraction = fractions_considered[f_MSE_ave_min_index]\n",
    "        \n",
    "    return optimal_fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform LOWESS on original race/ethnicity subset data\n",
    "def lowess_original_data(df, variable_of_interest, smoothing_factor_default):\n",
    "    optimal_fraction = smoothing_parameter(df, variable_of_interest, smoothing_factor_default)\n",
    "    lowess = sm.nonparametric.lowess(df['normalized_existing_installation'], df[variable_of_interest], frac=optimal_fraction)\n",
    "    lowess_x = list(zip(*lowess))[0]\n",
    "    lowess_y = list(zip(*lowess))[1]\n",
    "    f = interp1d(lowess_x, lowess_y, bounds_error=False)\n",
    "    lowess_x_min = int(min(lowess_x)) \n",
    "    lowess_x_max = int(max(lowess_x))\n",
    "    if variable_of_interest == 'median_income':\n",
    "        xnew = list(range(lowess_x_min,lowess_x_max,50))\n",
    "    else:\n",
    "        xnew = list(range(lowess_x_min,lowess_x_max,1))\n",
    "    y_original_data = f(xnew)\n",
    "    return (xnew, y_original_data, optimal_fraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform LOWESS on a bootstrap replica of the race/ethnicity subset data\n",
    "def lowess_bootstrap(df_sampled, variable_of_interest, xnew, optimal_fraction):\n",
    "    lowess_sample = sm.nonparametric.lowess(df_sampled['normalized_existing_installation'], df_sampled[variable_of_interest], frac=optimal_fraction)\n",
    "    lowess_x_sample = list(zip(*lowess_sample))[0]\n",
    "    lowess_y_sample = list(zip(*lowess_sample))[1]\n",
    "    f_sample = interp1d(lowess_x_sample, lowess_y_sample, bounds_error=False)\n",
    "    y_sample = f_sample(xnew)\n",
    "    return y_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowess_confidence_interval(df, variable_of_interest, CI, smoothing_factor_default):\n",
    "    # Perform LOWESS on the original race/ethnicity subset data\n",
    "    (xnew, y_original_data, optimal_fraction) = lowess_original_data(df, variable_of_interest, smoothing_factor_default)\n",
    "    Y = pd.DataFrame(y_original_data)\n",
    "\n",
    "    # Perform LOWESS on 1000 bootstrap replicas of the original race/ethnicity subset data\n",
    "    for i in range(1,1001):\n",
    "        rows = np.random.choice(df.index.values, len(df))\n",
    "        df_sampled = df.loc[rows]\n",
    "        y_sample = lowess_bootstrap(df_sampled, variable_of_interest, xnew, optimal_fraction)\n",
    "        Y.loc[:,i] = y_sample\n",
    "\n",
    "    # Calculate the confidence interval band\n",
    "    CI_high = Y.apply(lambda x: np.nanpercentile(x, (100 - (100-CI)/2)), axis=1)\n",
    "    CI_low  = Y.apply(lambda x: np.nanpercentile(x, ((100-CI)/2)), axis=1)\n",
    "    \n",
    "    Y['xnew'] = xnew\n",
    "    Y['CI_high'] = CI_high\n",
    "    Y['CI_low'] = CI_low\n",
    "    \n",
    "    return (Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asian-majority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_asian = lowess_confidence_interval(df_asian, variable_of_interest, CI, smoothing_factor_default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_asian.to_csv('Lowess_Asian_Results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Black-majority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_black = lowess_confidence_interval(df_black, variable_of_interest, CI, smoothing_factor_default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_black.to_csv('Lowess_Black_Results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hispanic-majority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_hisp = lowess_confidence_interval(df_hisp, variable_of_interest, CI, smoothing_factor_default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_hisp.to_csv('Lowess_Hispanic_Results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## White-majority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_white = lowess_confidence_interval(df_white, variable_of_interest, CI, smoothing_factor_default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_white.to_csv('Lowess_White_Results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No-majority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_no_majority = lowess_confidence_interval(df_no_majority, variable_of_interest, CI, smoothing_factor_default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_no_majority.to_csv('Lowess_No_Majority_Results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREATE FIGURE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subplot A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This subplot contains a histogram showing the number of census tracts by race/ethnicity as a function of the \n",
    "# variable of interest. Based on the user input, the variable of interest is either the median household income, \n",
    "# the percentage of households occupied by renters, or the surplus household income.\n",
    "\n",
    "fig, axHistx = plt.subplots(figsize=(20, 5))\n",
    "\n",
    "x_asian       = np.array(df_asian[variable_of_interest])\n",
    "x_black       = np.array(df_black[variable_of_interest])\n",
    "x_hisp        = np.array(df_hisp[variable_of_interest])\n",
    "x_white       = np.array(df_white[variable_of_interest])\n",
    "x_no_majority = np.array(df_no_majority[variable_of_interest])\n",
    "\n",
    "if variable_of_interest == 'median_income':\n",
    "    binwidth = 5000\n",
    "    bins = np.arange(20000, 250000+binwidth, binwidth)\n",
    "    axHistx.set_xlim([20000,260000])\n",
    "    axHistx.set_xscale('log')\n",
    "    fmt = '${x:,.0f}'\n",
    "    tick = mtick.StrMethodFormatter(fmt)\n",
    "    axHistx.xaxis.set_major_formatter(tick) \n",
    "    xticks = [25000,50000,75000,100000,150000,200000,250000]\n",
    "    plt.xticks(xticks, fontsize = 30)\n",
    "    plt.xticks(rotation = 45)\n",
    "elif variable_of_interest == 'rental_ratio':\n",
    "    binwidth = 5\n",
    "    bins = np.arange(0, 100+binwidth, binwidth)\n",
    "    axHistx.set_xlim([0,100])\n",
    "elif variable_of_interest == 'surplus_income':\n",
    "    binwidth = 5000\n",
    "    bins = np.arange(np.floor(min(data['surplus_income'])), np.ceil(max(data['surplus_income']))+binwidth, binwidth)\n",
    "    axHistx.set_xlim([np.floor(min(data['surplus_income'])),np.ceil(max(data['surplus_income']))+binwidth])\n",
    "    fmt = '${x:,.0f}'\n",
    "    tick = mtick.StrMethodFormatter(fmt)\n",
    "    axHistx.xaxis.set_major_formatter(tick) \n",
    "    xticks = [-100000,-50000,0,50000,100000,150000,200000]\n",
    "    plt.xticks(xticks, fontsize = 30)\n",
    "    plt.xticks(rotation = 45)\n",
    "else:\n",
    "    print('Error: Variable of interest is inappropriately assigned')\n",
    "\n",
    "axHistx.hist([x_white, x_hisp, x_black, x_asian, x_no_majority], bins =bins, stacked=True, color = ['blue', 'r', 'black', 'm','green'], alpha = 0.3)\n",
    "\n",
    "axHistx.tick_params(axis='x', labelsize=25)\n",
    "axHistx.tick_params(axis='y', labelsize=25)\n",
    "\n",
    "axHistx.set_ylabel('Tracts', fontsize = 30, labelpad =15)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subplot B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This subplot shows the rooftop PV installations relative to the available rooftop PV potential normalized by state\n",
    "# and grouped by the majority race/ethnicity as a function of the variable of interest. Based on the user input, the \n",
    "# variable of interest is either the median household income, the percentage of households occupied by renters, or the\n",
    "# surplus household income.\n",
    "\n",
    "fig, axLOWESS = plt.subplots(figsize=(20, 10))\n",
    "\n",
    "if variable_of_interest == 'median_income':\n",
    "    axLOWESS.set_xlabel('Median Household Income, 2013 USD', fontsize = 30, labelpad =15)\n",
    "    axLOWESS.set_xlim([20000,260000])\n",
    "    xticks = [25000,50000,75000,100000,150000,200000,250000]\n",
    "    axLOWESS.set_xscale('log')\n",
    "    fmt = '${x:,.0f}'\n",
    "    tick = mtick.StrMethodFormatter(fmt)\n",
    "    axLOWESS.xaxis.set_major_formatter(tick)\n",
    "    plt.xticks(xticks, fontsize = 30)\n",
    "    plt.xticks(rotation = 45)\n",
    "elif variable_of_interest == 'rental_ratio':\n",
    "    axLOWESS.set_xlabel('Percentage of households occupied by renters', fontsize = 30, labelpad =15)\n",
    "    axLOWESS.set_xlim([0,100])\n",
    "    xticks = [0,20,40,60,80,100]\n",
    "    plt.xticks(xticks, fontsize = 30)\n",
    "elif variable_of_interest == 'surplus_income':\n",
    "    binwidth = 5000\n",
    "    bins = np.arange(np.floor(min(data['surplus_income'])), np.ceil(max(data['surplus_income']))+binwidth, binwidth)\n",
    "    axHistx.set_xlim([np.floor(min(data['surplus_income'])),np.ceil(max(data['surplus_income']))+binwidth])\n",
    "    fmt = '${x:,.0f}'\n",
    "    tick = mtick.StrMethodFormatter(fmt)\n",
    "    axHistx.xaxis.set_major_formatter(tick) \n",
    "    xticks = [-100000,-50000,0,50000,100000,150000,200000]\n",
    "    plt.xticks(xticks, fontsize = 30)\n",
    "    plt.xticks(rotation = 45)\n",
    "else:\n",
    "    print('Error: Variable of interest is inappropriately assigned')\n",
    "    \n",
    "#No-majority \n",
    "axLOWESS.plot(Y_no_majority.xnew, Y_no_majority[0], '-', color = 'green', linewidth=2.0)\n",
    "axLOWESS.fill_between(Y_no_majority.xnew, Y_no_majority.CI_low, Y_no_majority.CI_high, facecolor='green', alpha=0.3)\n",
    "\n",
    "#Asian\n",
    "axLOWESS.plot(Y_asian.xnew, Y_asian[0], '-', color = 'm', linewidth=2.0)\n",
    "axLOWESS.fill_between(Y_asian.xnew, Y_asian.CI_low, Y_asian.CI_high, facecolor='m', alpha=0.3)\n",
    "\n",
    "#Black\n",
    "axLOWESS.plot(Y_black.xnew, Y_black[0], '-', color = 'black', linewidth=2.0)\n",
    "axLOWESS.fill_between(Y_black.xnew, Y_black.CI_low, Y_black.CI_high, facecolor='black', alpha=0.3)\n",
    "\n",
    "#Hispanic\n",
    "axLOWESS.plot(Y_hisp.xnew, Y_hisp[0], '-', color = 'red', linewidth=2.0)\n",
    "axLOWESS.fill_between(Y_hisp.xnew, Y_hisp.CI_low, Y_hisp.CI_high, facecolor='red', alpha=0.3)\n",
    "\n",
    "#White\n",
    "axLOWESS.plot(Y_white.xnew, Y_white[0], '-', color = 'blue', linewidth=2.0)\n",
    "axLOWESS.fill_between(Y_white.xnew, Y_white.CI_low, Y_white.CI_high, facecolor='blue', alpha=0.3)\n",
    "\n",
    "axLOWESS.set_ylabel('State Normalized \\nSolar Deployment', fontsize = 30, labelpad =15)\n",
    "axLOWESS.tick_params(axis='x', labelsize=25)\n",
    "axLOWESS.tick_params(axis='y', labelsize=25)\n",
    "\n",
    "upper_limit_y_axis = np.ceil(max([max(Y_no_majority.CI_high), max(Y_asian.CI_high), max(Y_black.CI_high), max(Y_hisp.CI_high), max(Y_white.CI_high)])) \n",
    "axLOWESS.set_ylim([0,upper_limit_y_axis])\n",
    "\n",
    "# Create legend\n",
    "asian_patch = mpatches.Patch(color='m', alpha = 0.3, label='Asian')\n",
    "black_patch = mpatches.Patch(color='black', alpha = 0.3, label='Black')\n",
    "hisp_patch = mpatches.Patch(color='r', alpha = 0.3, label='Hispanic')\n",
    "white_patch = mpatches.Patch(color='blue', alpha = 0.3, label='White')\n",
    "no_majority_patch = mpatches.Patch(color='green', alpha = 0.3, label='No-Majority')\n",
    "plt.legend(handles=[no_majority_patch, asian_patch, black_patch, hisp_patch, white_patch],\n",
    "               fontsize=25,loc='upper left', shadow=False, labelspacing =0.7)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subplot C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This subplot shows the state-normalized rooftop PV installations  normalized relative to the rooftop adoption of \n",
    "# no majority census tracts and grouped by the majority race/ethnicity as a function of the variable of interest. \n",
    "# Based on the user input, the variable of interest is either the median household income, the percentage of households\n",
    "# occupied by renters, or the surplus household income.\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "\n",
    "# Installations relative to no-majority census tracts\n",
    "lower_bound = int(min(Y_no_majority.xnew))\n",
    "upper_bound = int(max(Y_no_majority.xnew))\n",
    "\n",
    "if variable_of_interest == 'median_income':\n",
    "    ax.set_xlabel('Median Household Income, 2013 USD', fontsize = 30, labelpad =15)\n",
    "    ax.set_xlim([20000,260000])\n",
    "    xticks = [25000,50000,75000,100000,150000,200000,250000]\n",
    "    ax.set_xscale('log')\n",
    "    fmt = '${x:,.0f}'\n",
    "    tick = mtick.StrMethodFormatter(fmt)\n",
    "    ax.xaxis.set_major_formatter(tick)\n",
    "    plt.xticks(xticks, fontsize = 30)\n",
    "    plt.xticks(rotation = 45)\n",
    "    xvals = np.linspace(lower_bound, upper_bound, int((upper_bound-lower_bound)/50))\n",
    "elif variable_of_interest == 'rental_ratio':\n",
    "    axLOWESS.set_xlabel('Percentage of households occupied by renters', fontsize = 30, labelpad =15)\n",
    "    axLOWESS.set_xlim([0,100])\n",
    "    xticks = [0,20,40,60,80,100]\n",
    "    plt.xticks(xticks, fontsize = 30)\n",
    "    xvals = np.linspace(lower_bound, upper_bound, 100)\n",
    "elif variable_of_interest == 'surplus_income':\n",
    "    binwidth = 5000\n",
    "    bins = np.arange(np.floor(min(data['surplus_income'])), np.ceil(max(data['surplus_income']))+binwidth, binwidth)\n",
    "    axHistx.set_xlim([np.floor(min(data['surplus_income'])),np.ceil(max(data['surplus_income']))+binwidth])\n",
    "    fmt = '${x:,.0f}'\n",
    "    tick = mtick.StrMethodFormatter(fmt)\n",
    "    axHistx.xaxis.set_major_formatter(tick) \n",
    "    xticks = [-100000,-50000,0,50000,100000,150000,200000]\n",
    "    plt.xticks(xticks, fontsize = 30)\n",
    "    plt.xticks(rotation = 45)\n",
    "    xvals = np.linspace(lower_bound, upper_bound, int((upper_bound-lower_bound)/50))\n",
    "else:\n",
    "    print('Error: Variable of interest is inappropriately assigned')\n",
    "\n",
    "\n",
    "# No-majority\n",
    "yinterp_no_majority = np.interp(xvals, Y_no_majority.xnew, Y_no_majority[0])\n",
    "relative_group  = yinterp_no_majority\n",
    "yinterp_no_majority_CI_low = np.interp(xvals, Y_no_majority.xnew, Y_no_majority.CI_low)\n",
    "yinterp_no_majority_CI_high = np.interp(xvals, Y_no_majority.xnew, Y_no_majority.CI_high)\n",
    "relative_advantage_no_majority = (yinterp_no_majority-relative_group)/relative_group*100\n",
    "relative_advantage_no_majority_CI_low = (yinterp_no_majority_CI_low-relative_group)/relative_group*100\n",
    "relative_advantage_no_majority_CI_high = (yinterp_no_majority_CI_high-relative_group)/relative_group*100\n",
    "ax.plot(xvals,relative_advantage_no_majority, color = 'green', linewidth=2.0)\n",
    "ax.fill_between(xvals, relative_advantage_no_majority_CI_low, relative_advantage_no_majority_CI_high, facecolor='green', alpha=0.25)\n",
    "\n",
    "# Asian\n",
    "xvals_new = xvals[np.logical_and(xvals>=min(Y_asian.xnew),xvals<max(Y_asian.xnew))]\n",
    "yinterp_no_majority_new = np.interp(xvals_new, Y_no_majority.xnew, Y_no_majority[0])\n",
    "relative_group_new  = yinterp_no_majority_new\n",
    "yinterp_asian = np.interp(xvals_new, Y_asian.xnew, Y_asian[0])\n",
    "yinterp_asian_CI_low = np.interp(xvals_new, Y_asian.xnew, Y_asian.CI_low)\n",
    "yinterp_asian_CI_high = np.interp(xvals_new, Y_asian.xnew, Y_asian.CI_high)\n",
    "relative_advantage_asian = (yinterp_asian-relative_group_new)/relative_group_new*100\n",
    "relative_advantage_asian_CI_low = (yinterp_asian_CI_low-relative_group_new)/relative_group_new*100\n",
    "relative_advantage_asian_CI_high = (yinterp_asian_CI_high-relative_group_new)/relative_group_new*100\n",
    "ax.plot(xvals_new,relative_advantage_asian, color = 'm', linewidth=2.0)\n",
    "ax.fill_between(xvals_new, relative_advantage_asian_CI_low, relative_advantage_asian_CI_high, facecolor='m', alpha=0.25)\n",
    "\n",
    "# Black\n",
    "xvals_new = xvals[np.logical_and(xvals>=min(Y_black.xnew),xvals<max(Y_black.xnew))]\n",
    "yinterp_no_majority_new = np.interp(xvals_new, Y_no_majority.xnew, Y_no_majority[0])\n",
    "relative_group_new  = yinterp_no_majority_new\n",
    "yinterp_black = np.interp(xvals_new, Y_black.xnew, Y_black[0])\n",
    "yinterp_black_CI_low = np.interp(xvals_new, Y_black.xnew, Y_black.CI_low)\n",
    "yinterp_black_CI_high = np.interp(xvals_new, Y_black.xnew, Y_black.CI_high)\n",
    "relative_advantage_black = (yinterp_black-relative_group_new)/relative_group_new*100\n",
    "relative_advantage_black_CI_low = (yinterp_black_CI_low-relative_group_new)/relative_group_new*100\n",
    "relative_advantage_black_CI_high = (yinterp_black_CI_high-relative_group_new)/relative_group_new*100\n",
    "ax.plot(xvals_new,relative_advantage_black, color = 'black', linewidth=2.0)\n",
    "ax.fill_between(xvals_new, relative_advantage_black_CI_low, relative_advantage_black_CI_high, facecolor='black', alpha=0.25)\n",
    "\n",
    "# Hispanic\n",
    "xvals_new = xvals[np.logical_and(xvals>=min(Y_hisp.xnew),xvals<max(Y_hisp.xnew))]\n",
    "yinterp_no_majority_new = np.interp(xvals_new, Y_no_majority.xnew, Y_no_majority[0])\n",
    "relative_group_new  = yinterp_no_majority_new\n",
    "yinterp_hisp = np.interp(xvals_new, Y_hisp.xnew, Y_hisp[0])\n",
    "yinterp_hisp_CI_low = np.interp(xvals_new, Y_hisp.xnew, Y_hisp.CI_low)\n",
    "yinterp_hisp_CI_high = np.interp(xvals_new, Y_hisp.xnew, Y_hisp.CI_high)\n",
    "relative_advantage_hisp = (yinterp_hisp-relative_group_new)/relative_group_new*100\n",
    "relative_advantage_hisp_CI_low = (yinterp_hisp_CI_low-relative_group_new)/relative_group_new*100\n",
    "relative_advantage_hisp_CI_high = (yinterp_hisp_CI_high-relative_group_new)/relative_group_new*100\n",
    "ax.plot(xvals_new,relative_advantage_hisp, color = 'r', linewidth=2.0)\n",
    "ax.fill_between(xvals_new, relative_advantage_hisp_CI_low, relative_advantage_hisp_CI_high, facecolor='r', alpha=0.25)\n",
    "\n",
    "# White\n",
    "xvals_new = xvals[np.logical_and(xvals>=min(Y_white.xnew),xvals<max(Y_white.xnew))]\n",
    "yinterp_no_majority_new = np.interp(xvals_new, Y_no_majority.xnew, Y_no_majority[0])\n",
    "relative_group_new  = yinterp_no_majority_new\n",
    "yinterp_white = np.interp(xvals_new, Y_white.xnew, Y_white[0])\n",
    "yinterp_white_CI_low = np.interp(xvals_new, Y_white.xnew, Y_white.CI_low)\n",
    "yinterp_white_CI_high = np.interp(xvals_new, Y_white.xnew, Y_white.CI_high)\n",
    "relative_advantage_white = (yinterp_white-relative_group_new)/relative_group_new*100\n",
    "relative_advantage_white_CI_low = (yinterp_white_CI_low-relative_group_new)/relative_group_new*100\n",
    "relative_advantage_white_CI_high = (yinterp_white_CI_high-relative_group_new)/relative_group_new*100\n",
    "ax.plot(xvals_new,relative_advantage_white, color = 'blue', linewidth=2.0)\n",
    "ax.fill_between(xvals_new, relative_advantage_white_CI_low, relative_advantage_white_CI_high, facecolor='blue', alpha=0.25)\n",
    "\n",
    "ax.set_ylabel('Solar Deployment Relative\\nto No-Majority Census Tracts', fontsize = 30, labelpad =15)\n",
    "ax.tick_params(axis='y', labelsize=25)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Relative Advantage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nanmean(relative_advantage_black)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nanmean(relative_advantage_hisp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nanmean(relative_advantage_white)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nanmean(relative_advantage_asian) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
